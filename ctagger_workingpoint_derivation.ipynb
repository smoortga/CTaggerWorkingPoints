{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Charm-tagging working points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import ROOT\n",
    "import getpass\n",
    "import uproot\n",
    "import awkward\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import numpy as np\n",
    "from tqdm import tqdm,tqdm_notebook\n",
    "from itertools import permutations\n",
    "from IPython.display import HTML, display\n",
    "from array import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuration parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = os.listdir(\"/eos/cms/store/group/phys_btag/performance/UL18/MC/TTToHadronic_TuneCP5_13TeV-powheg-pythia8_RunIISummer19UL18MiniAOD-106X_upgrade2018_realistic_v11_L1v1/hadronic/\")\n",
    "#a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "year_label = \"2018UL\"\n",
    "sample = \"fully-hadronic t#bar{t}\"\n",
    "\n",
    "min_pt = 20\n",
    "max_abs_eta = 2.5\n",
    "\n",
    "\n",
    "nfiles = 10\n",
    "\n",
    "\n",
    "#files_path = ['root://xrootd-cms.infn.it//store/user/smoortga/BTagServiceWork/CTaggerWPs_2017_UltraLegacy/QCD_Pt_80to120_TuneCP5_13TeV_pythia8_RunIISummer19UL17MiniAOD-106X_mc2017_realistic_v6-v2_MINIAODSIM/QCD_Pt_80to120_TuneCP5_13TeV_pythia8/crab_BTagAnalyzer_CTagWP_2017_UltraLegacy/200116_133349/0000/JetTree_mc_%i.root'%idx for idx in range(1,nfiles+1)]\n",
    "files_path = ['root://xrootd-cms.infn.it//eos/cms/store/group/phys_btag/performance/UL18/MC/TTToHadronic_TuneCP5_13TeV-powheg-pythia8_RunIISummer19UL18MiniAOD-106X_upgrade2018_realistic_v11_L1v1/hadronic/%s'%a[idx] for idx in range(1,nfiles+1)]\n",
    "\n",
    "tree_directory = 'btagana/ttree'\n",
    "branches=[\"nJet\",\n",
    "          \"Jet_pt\",\n",
    "          \"Jet_eta\",\n",
    "          'Jet_flavourCleaned',\n",
    "          'Jet_tightID',\n",
    "          #'Jet_pileup_looseID',\n",
    "          'Jet_DeepFlavourBDisc',\n",
    "          'Jet_DeepFlavourCvsLDisc',\n",
    "          'Jet_DeepFlavourCvsBDisc',\n",
    "          'Jet_DeepCSVBDisc',\n",
    "          'Jet_DeepCSVCvsLDisc',\n",
    "          'Jet_DeepCSVCvsBDisc',\n",
    "         ]\n",
    "taggers = ['Jet_DeepFlavourBDisc',\n",
    "           'Jet_DeepFlavourCvsLDisc',\n",
    "           'Jet_DeepFlavourCvsBDisc',\n",
    "           'Jet_DeepCSVBDisc',\n",
    "           'Jet_DeepCSVCvsLDisc',\n",
    "           'Jet_DeepCSVCvsBDisc',\n",
    "          ]\n",
    "flavours = [\"b\",\"c\",\"l\"]\n",
    "\n",
    "# working points\n",
    "min_val = 0\n",
    "max_val = 1\n",
    "precision = 0.0001\n",
    "max_niter = 500\n",
    "wp_arr = [ # tager mistag rates: [mistag_eff_light,mistag_eff_b]\n",
    "    [\"loose\",[0.9,0.35]],\n",
    "    [\"medium\",[0.25,0.25]],\n",
    "    [\"tight\",[0.03,0.20]]\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tchain(fpath,tpath,branchlist,steps=None):    \n",
    "    return uproot.tree.iterate(path=fpath,\n",
    "                            treepath=tpath,\n",
    "                            branches=branchlist,\n",
    "                            entrysteps=steps)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Grid certificate (optional)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# password = getpass.getpass(\"Enter Password for grid certificate: \")\n",
    "# proxy_cmd = \"voms-proxy-init --rfc --voms cms -valid 192:00\"\n",
    "# os.system('echo %s | %s' % (password, proxy_cmd))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get info from trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees = tchain(files_path,tree_directory,branches) \n",
    "\n",
    "discriminator_dict = {}\n",
    "for tagger in taggers:\n",
    "    discriminator_dict[tagger]={}\n",
    "    discriminator_dict[\"Jet_pt\"]={}\n",
    "    discriminator_dict[\"Jet_eta\"]={}\n",
    "    #discriminator_dict[\"nPV\"]={}\n",
    "    for flav in flavours:\n",
    "        discriminator_dict[tagger][flav]=[]\n",
    "        discriminator_dict[\"Jet_pt\"][flav]=[]\n",
    "        discriminator_dict[\"Jet_eta\"][flav]=[]\n",
    "        #discriminator_dict[\"nPV\"][flav]=[]\n",
    "\n",
    "        \n",
    "# for branches in tqdm(trees,\n",
    "#                     total=n_subtrees,\n",
    "#                     desc=\"Progress\"):\n",
    "\n",
    "nevents = 0\n",
    "\n",
    "for idx,branches in enumerate(trees): \n",
    "    print \"running tree number %i: %i events processed\"%(idx,nevents)\n",
    "    nevents += len(branches['nJet'])\n",
    "    #plt.hist(branches['Jet_flavourCleaned'].flatten())\n",
    "    eta_mask = abs(branches['Jet_eta']) < max_abs_eta\n",
    "    pt_mask = branches['Jet_pt'] > min_pt\n",
    "    jetID_mask = branches['Jet_tightID'] == 1\n",
    "    flavour_mask={}\n",
    "    for flav in flavours:\n",
    "        if flav == \"b\": flavour_mask[flav] = branches['Jet_flavourCleaned'] == 5\n",
    "        elif flav == \"c\": flavour_mask[flav] = branches['Jet_flavourCleaned'] == 4\n",
    "        elif flav == \"l\": flavour_mask[flav] = (branches['Jet_flavourCleaned'] >= 0) * (branches['Jet_flavourCleaned'] != 4) * (branches['Jet_flavourCleaned'] != 5)\n",
    "    \n",
    "    \n",
    "    \n",
    "    for tagger in taggers:\n",
    "        for flav in flavours:\n",
    "            array_tmp = np.asarray(branches[tagger][eta_mask & pt_mask & jetID_mask & flavour_mask[flav]].flatten())\n",
    "            discriminator_dict[tagger][flav] = np.concatenate((discriminator_dict[tagger][flav],array_tmp))\n",
    "    \n",
    "    for flav in flavours:\n",
    "        array_tmp_pt = np.asarray(branches[\"Jet_pt\"][eta_mask & pt_mask & jetID_mask & flavour_mask[flav]].flatten())\n",
    "        discriminator_dict[\"Jet_pt\"][flav] = np.concatenate((discriminator_dict[\"Jet_pt\"][flav],array_tmp_pt))\n",
    "            \n",
    "        array_tmp_eta = np.asarray(branches[\"Jet_eta\"][eta_mask & pt_mask & jetID_mask & flavour_mask[flav]].flatten())\n",
    "        discriminator_dict[\"Jet_eta\"][flav] = np.concatenate((discriminator_dict[\"Jet_eta\"][flav],array_tmp_eta))\n",
    "            \n",
    "            \n",
    "\n",
    "#pprint.pprint(discriminator_dict)\n",
    "print \"Processed %i events\"%nevents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calculating working points according to some predefined mistags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "out_dict = {}\n",
    "\n",
    "def distance(current,target):\n",
    "    return np.sqrt((current[0]-target[0])**2+(current[1]-target[1])**2)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for tagger in [\"DeepCSV\",\"DeepFlavour\"]:\n",
    "    out_dict[tagger]={}\n",
    "    for wp,wp_mistag in wp_arr:\n",
    "        out_dict[tagger][wp]={}\n",
    "        \n",
    "        stepsize=0.1\n",
    "        decay = 0.9\n",
    "        \n",
    "        start_cut = [0.,0.] # CvsL , CvsB\n",
    "        start_mistag = [1.,1.] # mistag light, mistag b\n",
    "        \n",
    "        current_best_cut = start_cut\n",
    "        current_best_mistag = start_mistag\n",
    "        niter=0\n",
    "        curr_tagger = \"CvsL\"\n",
    "        while distance(current_best_mistag,wp_mistag) > precision:\n",
    "            if curr_tagger == \"CvsL\":\n",
    "                if current_best_mistag[0]>wp_mistag[0]: current_best_cut=[min(current_best_cut[0]+stepsize,max_val),current_best_cut[1]]\n",
    "                elif current_best_mistag[0]<wp_mistag[0]:current_best_cut=[max(current_best_cut[0]-stepsize,min_val),current_best_cut[1]]\n",
    "                curr_tagger = \"CvsB\"\n",
    "\n",
    "            elif curr_tagger == \"CvsB\":\n",
    "                if current_best_mistag[1]>wp_mistag[1]: current_best_cut=[current_best_cut[0],min(current_best_cut[1]+stepsize,max_val)]\n",
    "                elif current_best_mistag[0]<wp_mistag[0]: current_best_cut=[current_best_cut[0],max(current_best_cut[1]-stepsize,min_val)]\n",
    "                curr_tagger = \"CvsL\"\n",
    "\n",
    "\n",
    "            tag_mask_light = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']>current_best_cut[0])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['l']>current_best_cut[1])\n",
    "            all_light = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'])\n",
    "            tagged_light = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'][tag_mask_light])\n",
    "            eff_light = float(tagged_light) / float(all_light)\n",
    "\n",
    "            tag_mask_b = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']>current_best_cut[0])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['b']>current_best_cut[1])\n",
    "            all_b = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'])\n",
    "            tagged_b = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'][tag_mask_b])\n",
    "            eff_b = float(tagged_b) / float(all_b)\n",
    "\n",
    "            tag_mask_c = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']>current_best_cut[0])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['c']>current_best_cut[1])\n",
    "            all_c = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'])\n",
    "            tagged_c = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'][tag_mask_c])\n",
    "            eff_c = float(tagged_c) / float(all_c)\n",
    "\n",
    "            current_best_mistag = [eff_light,eff_b]\n",
    "\n",
    "            stepsize *=decay\n",
    "\n",
    "\n",
    "            niter+=1\n",
    "            if niter>max_niter: break\n",
    "\n",
    "        print tagger, wp #, eff_c,current_best_mistag,current_best_cut,distance(current_best_mistag,wp_mistag)\n",
    "        out_dict[tagger][wp][\"cut CvsL\"] = current_best_cut[0]\n",
    "        out_dict[tagger][wp][\"cut CvsB\"] = current_best_cut[1]\n",
    "        out_dict[tagger][wp][\"Eff charm\"] = eff_c\n",
    "        out_dict[tagger][wp][\"Eff light\"] = current_best_mistag[0]\n",
    "        out_dict[tagger][wp][\"Eff bottom\"] = current_best_mistag[1]\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "data = [[\"Tagger\",\"WP\",\"cut CvsL\",\"cut CvsB\",\"Eff charm\",\"Eff bottom\",\"Eff light\"],\n",
    "        [\"DeepCSV\",\"loose\",\"%.3f\"%out_dict[\"DeepCSV\"][\"loose\"][\"cut CvsL\"],\"%.3f\"%out_dict[\"DeepCSV\"][\"loose\"][\"cut CvsB\"],\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"loose\"][\"Eff charm\"]),\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"loose\"][\"Eff bottom\"]),\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"loose\"][\"Eff light\"])],\n",
    "        [\"\",\"medium\",\"%.3f\"%out_dict[\"DeepCSV\"][\"medium\"][\"cut CvsL\"],\"%.3f\"%out_dict[\"DeepCSV\"][\"medium\"][\"cut CvsB\"],\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"medium\"][\"Eff charm\"]),\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"medium\"][\"Eff bottom\"]),\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"medium\"][\"Eff light\"])],\n",
    "        [\"\",\"tight\",\"%.3f\"%out_dict[\"DeepCSV\"][\"tight\"][\"cut CvsL\"],\"%.3f\"%out_dict[\"DeepCSV\"][\"tight\"][\"cut CvsB\"],\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"tight\"][\"Eff charm\"]),\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"tight\"][\"Eff bottom\"]),\"%.1f%%\"%(100*out_dict[\"DeepCSV\"][\"tight\"][\"Eff light\"])],\n",
    "        [\"\",\"\",\"\",\"\",\"\",\"\",\"\"],\n",
    "        [\"DeepJet\",\"loose\",\"%.3f\"%out_dict[\"DeepFlavour\"][\"loose\"][\"cut CvsL\"],\"%.3f\"%out_dict[\"DeepFlavour\"][\"loose\"][\"cut CvsB\"],\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"loose\"][\"Eff charm\"]),\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"loose\"][\"Eff bottom\"]),\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"loose\"][\"Eff light\"])],\n",
    "        [\"\",\"medium\",\"%.3f\"%out_dict[\"DeepFlavour\"][\"medium\"][\"cut CvsL\"],\"%.3f\"%out_dict[\"DeepFlavour\"][\"medium\"][\"cut CvsB\"],\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"medium\"][\"Eff charm\"]),\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"medium\"][\"Eff bottom\"]),\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"medium\"][\"Eff light\"])],\n",
    "        [\"\",\"tight\",\"%.3f\"%out_dict[\"DeepFlavour\"][\"tight\"][\"cut CvsL\"],\"%.3f\"%out_dict[\"DeepFlavour\"][\"tight\"][\"cut CvsB\"],\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"tight\"][\"Eff charm\"]),\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"tight\"][\"Eff bottom\"]),\"%.1f%%\"%(100*out_dict[\"DeepFlavour\"][\"tight\"][\"Eff light\"])],\n",
    "         \n",
    "       ]\n",
    "\n",
    "display(HTML(\n",
    "   '<table><tr>{}</tr></table>'.format(\n",
    "       '</tr><tr>'.join(\n",
    "           '<td>{}</td>'.format('</td><td>'.join(str(_) for _ in row)) for row in data)\n",
    "       )\n",
    "))\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "ROOT.gStyle.SetOptStat(0)\n",
    "\n",
    "canvas_dict = {}\n",
    "plot_dict = {}\n",
    "legend_dict = {}\n",
    "lines_dict = {}\n",
    "\n",
    "\n",
    "latex_year = ROOT.TLatex()\n",
    "latex_year.SetTextFont(43)\n",
    "latex_year.SetTextSize(28)\n",
    "latex_year.SetTextAlign(32)\n",
    "\n",
    "latex_cms = ROOT.TLatex()\n",
    "latex_cms.SetTextFont(43)\n",
    "latex_cms.SetTextSize(30)\n",
    "latex_cms.SetTextAlign(11)\n",
    "\n",
    "latex_topology = ROOT.TLatex()\n",
    "latex_topology.SetTextFont(43)\n",
    "latex_topology.SetTextSize(24)\n",
    "latex_topology.SetTextAlign(31)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "for tagger in [\"DeepCSV\",\"DeepFlavour\"]:\n",
    "\n",
    "    disc_min = 0\n",
    "    disc_max = 1\n",
    "    ncuts = 300\n",
    "    \n",
    "    plot_dict[tagger] = {}\n",
    "    plot_dict[tagger][\"Plot_2D_B\"] = ROOT.TH2D(\"Plot_2D_B%s\"%tagger,\" ;%s CvsL;%s CvsB\"%(tagger.replace(\"Flavour\",\"Jet\"),tagger.replace(\"Flavour\",\"Jet\")),ncuts,disc_min,disc_max,ncuts,disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"] = ROOT.TH2D(\"Plot_2D_C%s\"%tagger,\" ;%s CvsL;%s CvsB\"%(tagger.replace(\"Flavour\",\"Jet\"),tagger.replace(\"Flavour\",\"Jet\")),ncuts,disc_min,disc_max,ncuts,disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"] = ROOT.TH2D(\"Plot_2D_DUSG%s\"%tagger,\" ;%s CvsL;%s CvsB\"%(tagger.replace(\"Flavour\",\"Jet\"),tagger.replace(\"Flavour\",\"Jet\")),ncuts,disc_min,disc_max,ncuts,disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "    \n",
    "    #     \n",
    "#     Plot_2D_B = ROOT.TH2D(\"Plot_2D_B%s\"%tagger,\" ;%s CvsL;%s CvsB\"%(tagger.replace(\"Flavour\",\"Jet\"),tagger.replace(\"Flavour\",\"Jet\")),ncuts,disc_min,disc_max,ncuts,disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "#     Plot_2D_C = ROOT.TH2D(\"Plot_2D_C%s\"%tagger,\" ;%s CvsL;%s CvsB\"%(tagger.replace(\"Flavour\",\"Jet\"),tagger.replace(\"Flavour\",\"Jet\")),ncuts,disc_min,disc_max,ncuts,disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "#     Plot_2D_DUSG = ROOT.TH2D(\"Plot_2D_DUSG%s\"%tagger,\" ;%s CvsL;%s CvsB\"%(tagger.replace(\"Flavour\",\"Jet\"),tagger.replace(\"Flavour\",\"Jet\")),ncuts,disc_min,disc_max,ncuts,disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "    \n",
    "    min_n_flav = min(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']),len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']),len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']))\n",
    "    \n",
    "    \n",
    "    plot_dict[tagger][\"Plot_2D_B\"].FillN(min_n_flav,discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['b'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'])))\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].FillN(min_n_flav,discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['c'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'])))\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].FillN(min_n_flav,discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['l'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'])))\n",
    "\n",
    "    \n",
    "#     Plot_2D_B.FillN(min_n_flav,discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['b'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'])))\n",
    "#     Plot_2D_C.FillN(min_n_flav,discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['c'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'])))\n",
    "#     Plot_2D_DUSG.FillN(min_n_flav,discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['l'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'])))\n",
    "\n",
    "    \n",
    "    #Plot_2D_B.FillN(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']),discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['b'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'])))\n",
    "    #Plot_2D_C.FillN(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']),discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['c'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'])))\n",
    "    #Plot_2D_DUSG.FillN(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']),discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'],discriminator_dict['Jet_%sCvsBDisc'%tagger]['l'],np.ones(len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'])))\n",
    "\n",
    "    canvas_dict[tagger] = ROOT.TCanvas(\"c_%s\"%tagger,\"c_%s\"%tagger,700,600)\n",
    "    canvas_dict[tagger].cd()\n",
    "    ROOT.gPad.SetMargin(0.13,0.07,0.13,0.07)\n",
    "    legend_dict[tagger] = ROOT.TLegend(0.2,0.7,0.90,0.76)\n",
    "    legend_dict[tagger].SetNColumns(3)\n",
    "    legend_dict[tagger].SetFillColor(0)\n",
    "    legend_dict[tagger].SetFillStyle(0)\n",
    "    legend_dict[tagger].SetBorderSize(0)\n",
    "    \n",
    "    \n",
    "    \n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetYaxis().SetTitleOffset(1.1)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetYaxis().SetTitleSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetYaxis().SetLabelSize(0.045)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetYaxis().SetNdivisions(510)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetXaxis().SetTitleSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetXaxis().SetLabelSize(0.045)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetXaxis().SetNdivisions(505)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetZaxis().SetLabelSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].GetYaxis().SetTitleOffset(1.1)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].GetYaxis().SetTitleSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].GetYaxis().SetLabelSize(0.045)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].GetXaxis().SetTitleSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].GetXaxis().SetLabelSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].GetZaxis().SetLabelSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].GetYaxis().SetTitleOffset(1.1)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].GetYaxis().SetTitleSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].GetYaxis().SetLabelSize(0.045)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].GetXaxis().SetTitleSize(0.065)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].GetXaxis().SetLabelSize(0.055)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].GetZaxis().SetLabelSize(0.055)\n",
    "\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].SetMarkerColorAlpha(ROOT.kRed,0.2)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].SetFillColor(ROOT.kRed)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].SetMarkerStyle(6)\n",
    "    legend_dict[tagger].AddEntry(plot_dict[tagger][\"Plot_2D_B\"],\"b jets\",\"f\")\n",
    "    #ROOT.gPad.SetTickx(1)\n",
    "    #ROOT.gPad.SetTicky(1)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].GetYaxis().SetRangeUser(disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "    plot_dict[tagger][\"Plot_2D_B\"].Draw()\n",
    "\n",
    "\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].SetMarkerColorAlpha(8,0.2)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].SetFillColor(8)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].SetMarkerStyle(6)\n",
    "    legend_dict[tagger].AddEntry(plot_dict[tagger][\"Plot_2D_C\"],\"c jets\",\"f\")\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].GetYaxis().SetRangeUser(disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "    plot_dict[tagger][\"Plot_2D_C\"].Draw(\"same\")\n",
    "\n",
    "\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].SetMarkerColorAlpha(ROOT.kBlue,0.2)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].SetFillColor(ROOT.kBlue)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].SetMarkerStyle(6)\n",
    "    legend_dict[tagger].AddEntry(plot_dict[tagger][\"Plot_2D_DUSG\"],\"light jets\",\"f\")\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].GetYaxis().SetRangeUser(disc_min,disc_max + (disc_max-disc_min)/2.)\n",
    "    plot_dict[tagger][\"Plot_2D_DUSG\"].Draw(\"same\")\n",
    "\n",
    "    legend_dict[tagger].Draw(\"same\")\\\n",
    "    \n",
    "    wp_dict = {\"L\":[out_dict[tagger][\"loose\"][\"cut CvsL\"],out_dict[tagger][\"loose\"][\"cut CvsB\"],9,0.18],\"M\":[out_dict[tagger][\"medium\"][\"cut CvsL\"],out_dict[tagger][\"medium\"][\"cut CvsB\"],7,0.26],\"T\":[out_dict[tagger][\"tight\"][\"cut CvsL\"],out_dict[tagger][\"tight\"][\"cut CvsB\"],2,0.79]} \n",
    "    lines_dict[tagger] = {}\n",
    "    for wp,borders in wp_dict.iteritems():\n",
    "        lines_dict[tagger][wp+\"_h\"] = ROOT.TLine()\n",
    "        lines_dict[tagger][wp+\"_h\"].SetLineStyle(borders[2])\n",
    "        lines_dict[tagger][wp+\"_h\"].SetLineColor(1)\n",
    "        lines_dict[tagger][wp+\"_h\"].SetLineWidth(3)\n",
    "        lines_dict[tagger][wp+\"_h\"].DrawLine(borders[0],borders[1],1,borders[1])\n",
    "        lines_dict[tagger][wp+\"_v\"] = ROOT.TLine()\n",
    "        lines_dict[tagger][wp+\"_v\"].SetLineStyle(borders[2])\n",
    "        lines_dict[tagger][wp+\"_v\"].SetLineColor(1)\n",
    "        lines_dict[tagger][wp+\"_v\"].SetLineWidth(3)\n",
    "        lines_dict[tagger][wp+\"_v\"].DrawLine(borders[0],borders[1],borders[0],1.05)\n",
    "        lines_dict[tagger][wp+\"_txt\"] = ROOT.TPaveText(borders[0]+0.01,1-0.05,borders[0]+0.05,1.03,\"NB\")\n",
    "        lines_dict[tagger][wp+\"_txt\"].SetTextAlign(11)\n",
    "        lines_dict[tagger][wp+\"_txt\"].AddText(\"#bf{\"+wp+\"}\")\n",
    "        lines_dict[tagger][wp+\"_txt\"].SetTextFont(43)\n",
    "        lines_dict[tagger][wp+\"_txt\"].SetTextSize(22)\n",
    "        lines_dict[tagger][wp+\"_txt\"].SetFillColor(0)\n",
    "        lines_dict[tagger][wp+\"_txt\"].SetFillStyle(0)\n",
    "        lines_dict[tagger][wp+\"_txt\"].SetBorderSize(0)\n",
    "        lines_dict[tagger][wp+\"_txt\"].Draw(\"same\")\n",
    "    \n",
    "    latex_year.DrawLatexNDC(0.93,0.96,year_label+\" (13 TeV)\")\n",
    "    latex_cms.DrawLatexNDC(0.17,0.87,\"#bf{CMS} #it{Simulation}\")\n",
    "    latex_topology.DrawLatexNDC(0.92,0.87,sample)\n",
    "    latex_topology.DrawLatexNDC(0.92,0.80,\"p_{T}^{jet} > %i GeV, |#eta^{jet}| < %.1f\"%(min_pt,max_abs_eta))\n",
    "    \n",
    "    \n",
    "    canvas_dict[tagger].Draw()\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/2D_CvsL_CvsB_Scatter_%s.pdf\"%tagger)\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/2D_CvsL_CvsB_Scatter_%s.png\"%tagger)\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/2D_CvsL_CvsB_Scatter_%s.C\"%tagger)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy\n",
    "ncuts=20\n",
    "binning_dict = {} \n",
    "sorted_discriminator_dict = deepcopy(discriminator_dict)\n",
    "for tagger, flav_dicts in sorted_discriminator_dict.iteritems():\n",
    "    binning_dict[tagger]={}\n",
    "    for flav, values in flav_dicts.iteritems():\n",
    "        sorted_discriminator_dict[tagger][flav]=sorted(discriminator_dict[tagger][flav])\n",
    "        #binning_dict[tagger][flav] = []\n",
    "        indices = np.arange(0,len(sorted_discriminator_dict[tagger][flav]),len(sorted_discriminator_dict[tagger][flav])/ncuts)\n",
    "        binning_dict[tagger][flav] = [i for i in map(sorted_discriminator_dict[tagger][flav].__getitem__, indices) if i > 0]\n",
    "\n",
    "cuts = sorted(np.concatenate((binning_dict[tagger][\"b\"],binning_dict[tagger][\"l\"])))\n",
    "\n",
    "cuts2d = list(permutations(cuts,2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NRGBs = 11\n",
    "NCont = 255\n",
    "stops = np.arange(0,1.1,0.09)\n",
    "red = np.asarray( [255./255., 242./255., 234./255., 237./255., 230./255., 212./255., 156./255., 99./255., 45./255., 0./255.])\n",
    "green = np.asarray( [255./255., 243./255., 238./255., 238./255., 168./255., 101./255.,  45./255.,  0./255.,  0./255., 0./255.])\n",
    "blue = np.asarray( [255./255., 230./255.,  95./255.,  11./255.,   8./255.,   9./255.,   3./255.,  1./255.,  1./255., 0./255.])\n",
    "#Idx = TColor::CreateGradientColorTable(9, stops, red, green, blue, 255, alpha);\n",
    "ROOT.TColor.CreateGradientColorTable(NRGBs, stops, red, green, blue, NCont)\n",
    "ROOT.gStyle.SetNumberContours(99)\n",
    "\n",
    "latex_year = ROOT.TLatex()\n",
    "latex_year.SetTextFont(43)\n",
    "latex_year.SetTextSize(25)\n",
    "latex_year.SetTextAlign(11)\n",
    "\n",
    "latex_cms = ROOT.TLatex()\n",
    "latex_cms.SetTextFont(43)\n",
    "latex_cms.SetTextSize(27)\n",
    "latex_cms.SetTextAlign(11)\n",
    "\n",
    "latex_topology = ROOT.TLatex()\n",
    "latex_topology.SetTextFont(43)\n",
    "latex_topology.SetTextSize(22)\n",
    "latex_topology.SetTextAlign(31)\n",
    "\n",
    "latex_tagger = ROOT.TLatex()\n",
    "latex_tagger.SetTextFont(43)\n",
    "latex_tagger.SetTextSize(22)\n",
    "latex_tagger.SetTextAlign(31)\n",
    "\n",
    "nbins=100\n",
    "hist_dict = {}\n",
    "graph_dict = {}\n",
    "cont_dict = {}\n",
    "conttext_dict = {}\n",
    "wp_graph_dict = {}\n",
    "wp_text_dict = {}\n",
    "\n",
    "for tagger in [\"DeepCSV\",\"DeepFlavour\"]:\n",
    "    hist_dict[tagger] = ROOT.TH2D(\"efficiency_hist_%s\"%tagger,\" ;b jet misid. efficiency; light or gluon jet misid. efficiency\",nbins,0,1,nbins,0,1)\n",
    "    graph_dict[tagger] = ROOT.TGraph2D()#len(cuts2d))\n",
    "    \n",
    "    canvas_dict[tagger] = ROOT.TCanvas(\"c_%s\"%tagger,\"c_%s\"%tagger,700,600)\n",
    "    canvas_dict[tagger].cd()\n",
    "    ROOT.gPad.SetMargin(0.13,0.15,0.13,0.15)\n",
    "    \n",
    "    #\n",
    "    # DEFINE BOUNDARIES\n",
    "    #\n",
    "    left_point1 = (0,0.2)\n",
    "    left_point2 = (0.6,1.)\n",
    "    left_rico = float(left_point2[1]-left_point1[1])/(left_point2[0]-left_point1[0])\n",
    "    left_boundry = ROOT.TF1(\"left_boundry\",\"%.2f*(x-%.2f) + %.2f\"%(left_rico,left_point1[0],left_point1[1]),0,1)\n",
    "    left_boundry.SetLineWidth(10)\n",
    "    left_boundry.SetLineColor(1)\n",
    "    \n",
    "    \n",
    "    right_point1 = (0.3,0.)\n",
    "    right_point2 = (0.6,1.)\n",
    "    right_rico = float(right_point2[1]-right_point1[1])/(right_point2[0]-right_point1[0])\n",
    "    right_boundry = ROOT.TF1(\"right_boundry\",\"%.2f*(x-%.2f) + %.2f\"%(right_rico,right_point1[0],right_point1[1]),0,1)\n",
    "    right_boundry.SetLineWidth(10)\n",
    "    right_boundry.SetLineColor(1)\n",
    "\n",
    "    \n",
    "    counter = 0\n",
    "    for c in tqdm(cuts2d, position=0, leave=True):\n",
    "        tag_mask_light = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']>c[0])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['l']>c[1])\n",
    "        all_light = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'])\n",
    "        tagged_light = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['l'][tag_mask_light])\n",
    "        eff_light = float(tagged_light) / float(all_light)\n",
    "\n",
    "        tag_mask_b = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']>c[0])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['b']>c[1])\n",
    "        all_b = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'])\n",
    "        tagged_b = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['b'][tag_mask_b])\n",
    "        eff_b = float(tagged_b) / float(all_b)\n",
    "\n",
    "        tag_mask_c = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']>c[0])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['c']>c[1])\n",
    "        all_c = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'])\n",
    "        tagged_c = len(discriminator_dict['Jet_%sCvsLDisc'%tagger]['c'][tag_mask_c])\n",
    "        eff_c = float(tagged_c) / float(all_c)\n",
    "        \n",
    "        #hist_dict[tagger].SetBinContent(hist_dict[tagger].FindBin(eff_b,eff_light),eff_c)\n",
    "        #if eff_light < left_boundry.Eval(eff_b) and eff_light > right_boundry.Eval(eff_b):\n",
    "        graph_dict[tagger].SetPoint(counter,eff_b,eff_light,eff_c)\n",
    "        counter+=1\n",
    "    \n",
    "    \n",
    "    \n",
    "   \n",
    "    \n",
    "    hist_dict[tagger].Draw(\"\")\n",
    "    #left_boundry.Draw(\"same l\")\n",
    "    #right_boundry.Draw(\"same l\")\n",
    "    hist_dict[tagger].GetXaxis().SetRangeUser(0.03,1)\n",
    "    hist_dict[tagger].GetYaxis().SetRangeUser(0.03,1)\n",
    "    \n",
    "    hist_dict[tagger+\"_bis\"] = graph_dict[tagger].GetHistogram()\n",
    "    hist_dict[tagger+\"_bis\"].GetZaxis().SetTitle(\"charm jet efficiency\")\n",
    "    hist_dict[tagger+\"_bis\"].GetZaxis().CenterTitle()\n",
    "    hist_dict[tagger+\"_bis\"].GetZaxis().SetTitleOffset(1.1)\n",
    "    hist_dict[tagger+\"_bis\"].Smooth()\n",
    "    \n",
    "    hist_dict[tagger+\"_bis_discrete\"] = hist_dict[tagger+\"_bis\"].Clone()\n",
    "    contours = array(\"d\",[0.3,0.4,0.5,0.6,0.7,0.8,0.9])\n",
    "    hist_dict[tagger+\"_bis_discrete\"].SetContour(len(contours),array(\"d\",contours))\n",
    "    hist_dict[tagger+\"_bis_discrete\"].Draw(\"CONT same LIST\")\n",
    "    canvas_dict[tagger].Update()\n",
    "    \n",
    "    hist_dict[tagger+\"_bis\"].Draw(\"CONTZ same\")\n",
    "    \n",
    "    \n",
    "\n",
    "    conts = ROOT.gROOT.GetListOfSpecials().FindObject(\"contours\")\n",
    "    \n",
    "    for idx,cont in enumerate(conts):\n",
    "        gr=(cont.First()).Clone()\n",
    "#         cont_dict[tagger+\"_cont_\"+str(idx)].SetLineWidth(5)\n",
    "#         cont_dict[tagger+\"_cont_\"+str(idx)].SetLineColor(0)\n",
    "#         cont_dict[tagger+\"_cont_\"+str(idx)].Draw(\"C\")\n",
    "        x_values = array(\"d\",np.asarray(gr.GetX()))\n",
    "        y_values = array(\"d\",np.asarray(gr.GetY()))\n",
    "        cont_dict[tagger+\"_cont_\"+str(idx)] = ROOT.TGraph()\n",
    "        \n",
    "        \n",
    "        ii=0\n",
    "        for x,y in zip(x_values,y_values):\n",
    "            if y < left_boundry.Eval(x) and y > right_boundry.Eval(x): \n",
    "                cont_dict[tagger+\"_cont_\"+str(idx)].SetPoint(ii,x,y)\n",
    "                ii+=1\n",
    "        cont_dict[tagger+\"_cont_\"+str(idx)].SetLineWidth(5)\n",
    "        cont_dict[tagger+\"_cont_\"+str(idx)].SetLineColor(0)\n",
    "        cont_dict[tagger+\"_cont_\"+str(idx)].Draw(\"C\")\n",
    "        \n",
    "        index_text = int(len(array(\"d\",np.asarray(cont_dict[tagger+\"_cont_\"+str(idx)].GetX())))/1.3)\n",
    "        x_text = array(\"d\",np.asarray(cont_dict[tagger+\"_cont_\"+str(idx)].GetX()))[index_text]\n",
    "        y_text = array(\"d\",np.asarray(cont_dict[tagger+\"_cont_\"+str(idx)].GetY()))[index_text]\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)] = ROOT.TPaveText(x_text,y_text,x_text+0.01,y_text+0.01,\"NB\")\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].SetTextAlign(11)\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].AddText(\"%.1f\"%contours[idx])\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].SetTextFont(43)\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].SetTextAlign(11)\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].SetTextSize(22)\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].SetTextColor(0)\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].SetFillColor(0)\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].SetFillStyle(0)\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].SetBorderSize(0)\n",
    "        conttext_dict[tagger+\"_cont_text_\"+str(idx)].Draw(\"same\")\n",
    "    \n",
    "    wp_graph_dict[tagger] = {}\n",
    "    for wp_ in [\"loose\",\"medium\",\"tight\"]:\n",
    "        wp_graph_dict[tagger][wp_]=ROOT.TGraph()\n",
    "        wp_graph_dict[tagger][wp_].SetPoint(0,out_dict[tagger][wp_][\"Eff bottom\"],out_dict[tagger][wp_][\"Eff light\"])\n",
    "        wp_graph_dict[tagger][wp_].SetMarkerColor(ROOT.kCyan+1)\n",
    "        wp_graph_dict[tagger][wp_].SetMarkerStyle(34)\n",
    "        wp_graph_dict[tagger][wp_].SetMarkerSize(2)\n",
    "        #wp_graph_dict[tagger][wp_].Draw(\"p\")\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_] = ROOT.TPaveText(out_dict[tagger][wp_][\"Eff bottom\"],out_dict[tagger][wp_][\"Eff light\"],out_dict[tagger][wp_][\"Eff bottom\"]+0.01,out_dict[tagger][wp_][\"Eff light\"]+0.01,\"NB\")\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].SetTextAlign(22)\n",
    "        if wp_ == \"loose\": wp_text_dict[tagger+\"_cont_text_\"+wp_].AddText(\"#bf{L}\")\n",
    "        if wp_ == \"medium\": wp_text_dict[tagger+\"_cont_text_\"+wp_].AddText(\"#bf{M}\")\n",
    "        if wp_ == \"tight\": wp_text_dict[tagger+\"_cont_text_\"+wp_].AddText(\"#bf{T}\")\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].SetTextFont(43)\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].SetTextAlign(11)\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].SetTextSize(22)\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].SetTextColor(ROOT.kCyan)\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].SetFillColor(0)\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].SetFillStyle(0)\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].SetBorderSize(0)\n",
    "        wp_text_dict[tagger+\"_cont_text_\"+wp_].Draw(\"same\")\n",
    "    \n",
    "    \n",
    "    ROOT.gPad.SetLogy(1)\n",
    "    ROOT.gPad.SetLogx(1)\n",
    "    ROOT.gPad.SetTickx(1)\n",
    "    ROOT.gPad.SetTicky(1)\n",
    "    ROOT.gPad.RedrawAxis()\n",
    "    \n",
    "    latex_year.DrawLatexNDC(0.14,0.87,year_label+\" (13 TeV)\")\n",
    "    latex_cms.DrawLatexNDC(0.14,0.92,\"#bf{CMS} #it{Simulation}\")\n",
    "    latex_tagger.DrawLatexNDC(0.89,0.97,\"#bf{%s c tagger}\"%tagger.replace(\"Flavour\",\"Jet\"))\n",
    "    latex_topology.DrawLatexNDC(0.89,0.925,sample)\n",
    "    latex_topology.DrawLatexNDC(0.89,0.875,\"p_{T}^{jet} > %i GeV, |#eta^{jet}| < %.1f\"%(min_pt,max_abs_eta))\n",
    "    \n",
    "    \n",
    "    canvas_dict[tagger].Draw()\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/EfficiencyMap_ctagger_%s.pdf\"%tagger)\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/EfficiencyMap_ctagger_%s.png\"%tagger)\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/EfficiencyMap_ctagger_%s.C\"%tagger)\n",
    "        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Efficiency vs pT/eta/nPV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "canvas_dict = {}\n",
    "hist_dict = {}\n",
    "legend_dict = {}\n",
    "\n",
    "pt_bins = [20,30,40,50,60,70,80,90,100,120,140,160,180,200,250,300]\n",
    "eta_bins = np.arange(-2.5,2.6,0.2)\n",
    "\n",
    "\n",
    "for tagger in [\"DeepCSV\",\"DeepFlavour\"]:\n",
    "    hist_dict[tagger]={}\n",
    "    legend_dict[tagger] = {}\n",
    "    canvas_dict[tagger] = ROOT.TCanvas(\"c_\"+tagger,\"c_\"+tagger,1200,800)\n",
    "    canvas_dict[tagger].Divide(3,2)\n",
    "    \n",
    "    # pt, c jets\n",
    "    canvas_dict[tagger].cd(1)\n",
    "    ROOT.gPad.SetMargin(0.15,0.05,0.15,0.2)\n",
    "    hist_dict[tagger][\"pt_c\"] = ROOT.TH1D(tagger+\"_pt_c\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_c\"].FillN(len(discriminator_dict['Jet_pt']['c']),discriminator_dict['Jet_pt']['c'],np.ones(len(discriminator_dict['Jet_pt']['c'])))\n",
    "    tag_mask_c_loose = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']>out_dict[tagger][\"loose\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['c']>out_dict[tagger][\"loose\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_loose_c\"] = ROOT.TH1D(tagger+\"_pt_loose_c\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_loose_c\"].FillN(len(discriminator_dict['Jet_pt']['c'][tag_mask_c_loose]),discriminator_dict['Jet_pt']['c'][tag_mask_c_loose],np.ones(len(discriminator_dict['Jet_pt']['c'][tag_mask_c_loose])))   \n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"] = hist_dict[tagger][\"pt_loose_c\"].Clone()\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].Divide(hist_dict[tagger][\"pt_c\"])\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].SetMarkerStyle(21)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].SetMarkerColor(ROOT.kRed)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetYaxis().SetRangeUser(0,1)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetYaxis().SetTitle(\"c jet efficiency\")\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetYaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetYaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetYaxis().SetTitleOffset(2.3)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetYaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetYaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetXaxis().SetTitle(\"jet p_{T} [GeV]\")\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetXaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetXaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetXaxis().SetTitleOffset(2.1)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetXaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].GetXaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"pt_loose_c_eff\"].Draw(\"p\")\n",
    "\n",
    "    hist_dict[tagger][\"pt_c\"] = ROOT.TH1D(tagger+\"_pt_c\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_c\"].FillN(len(discriminator_dict['Jet_pt']['c']),discriminator_dict['Jet_pt']['c'],np.ones(len(discriminator_dict['Jet_pt']['c'])))\n",
    "    tag_mask_c_medium = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']>out_dict[tagger][\"medium\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['c']>out_dict[tagger][\"medium\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_medium_c\"] = ROOT.TH1D(tagger+\"_pt_medium_c\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_medium_c\"].FillN(len(discriminator_dict['Jet_pt']['c'][tag_mask_c_medium]),discriminator_dict['Jet_pt']['c'][tag_mask_c_medium],np.ones(len(discriminator_dict['Jet_pt']['c'][tag_mask_c_medium])))   \n",
    "    hist_dict[tagger][\"pt_medium_c_eff\"] = hist_dict[tagger][\"pt_medium_c\"].Clone()\n",
    "    hist_dict[tagger][\"pt_medium_c_eff\"].Divide(hist_dict[tagger][\"pt_c\"])\n",
    "    hist_dict[tagger][\"pt_medium_c_eff\"].SetMarkerStyle(22)\n",
    "    hist_dict[tagger][\"pt_medium_c_eff\"].SetMarkerColor(ROOT.kBlue)\n",
    "    hist_dict[tagger][\"pt_medium_c_eff\"].Draw(\"p same\")\n",
    "\n",
    "    hist_dict[tagger][\"pt_c\"] = ROOT.TH1D(tagger+\"_pt_c\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_c\"].FillN(len(discriminator_dict['Jet_pt']['c']),discriminator_dict['Jet_pt']['c'],np.ones(len(discriminator_dict['Jet_pt']['c'])))\n",
    "    tag_mask_c_tight = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']>out_dict[tagger][\"tight\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['c']>out_dict[tagger][\"tight\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_tight_c\"] = ROOT.TH1D(tagger+\"_pt_tight_c\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_tight_c\"].FillN(len(discriminator_dict['Jet_pt']['c'][tag_mask_c_tight]),discriminator_dict['Jet_pt']['c'][tag_mask_c_tight],np.ones(len(discriminator_dict['Jet_pt']['c'][tag_mask_c_tight])))   \n",
    "    hist_dict[tagger][\"pt_tight_c_eff\"] = hist_dict[tagger][\"pt_tight_c\"].Clone()\n",
    "    hist_dict[tagger][\"pt_tight_c_eff\"].Divide(hist_dict[tagger][\"pt_c\"])\n",
    "    hist_dict[tagger][\"pt_tight_c_eff\"].SetMarkerStyle(28)\n",
    "    hist_dict[tagger][\"pt_tight_c_eff\"].SetMarkerColor(ROOT.kGreen+2)\n",
    "    hist_dict[tagger][\"pt_tight_c_eff\"].Draw(\"p same\")\n",
    "\n",
    "    legend_dict[tagger]['pt_c'] = ROOT.TLegend(0.15,0.82,0.9,0.99)\n",
    "    legend_dict[tagger]['pt_c'].SetNColumns(3)\n",
    "    legend_dict[tagger]['pt_c'].SetTextFont(43)\n",
    "    legend_dict[tagger]['pt_c'].SetTextSize(20)\n",
    "    legend_dict[tagger]['pt_c'].SetBorderSize(0)\n",
    "    legend_dict[tagger]['pt_c'].SetFillStyle(0)\n",
    "    legend_dict[tagger]['pt_c'].SetHeader(tagger.replace(\"Flavour\",\"Jet\") + \" c tagger\")\n",
    "    legend_dict[tagger]['pt_c'].AddEntry(hist_dict[tagger][\"pt_loose_c_eff\"],\"Loose\",\"p\")\n",
    "    legend_dict[tagger]['pt_c'].AddEntry(hist_dict[tagger][\"pt_medium_c_eff\"],\"Medium\",\"p\")\n",
    "    legend_dict[tagger]['pt_c'].AddEntry(hist_dict[tagger][\"pt_tight_c_eff\"],\"Tight\",\"p\")\n",
    "    legend_dict[tagger]['pt_c'].Draw('same')\n",
    "    \n",
    "    # pt, b jets\n",
    "    canvas_dict[tagger].cd(2)\n",
    "    ROOT.gPad.SetMargin(0.15,0.05,0.15,0.2)\n",
    "    hist_dict[tagger][\"pt_b\"] = ROOT.TH1D(tagger+\"_pt_b\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_b\"].FillN(len(discriminator_dict['Jet_pt']['b']),discriminator_dict['Jet_pt']['b'],np.ones(len(discriminator_dict['Jet_pt']['b'])))\n",
    "    tag_mask_b_loose = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']>out_dict[tagger][\"loose\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['b']>out_dict[tagger][\"loose\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_loose_b\"] = ROOT.TH1D(tagger+\"_pt_loose_b\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_loose_b\"].FillN(len(discriminator_dict['Jet_pt']['b'][tag_mask_b_loose]),discriminator_dict['Jet_pt']['b'][tag_mask_b_loose],np.ones(len(discriminator_dict['Jet_pt']['b'][tag_mask_b_loose])))   \n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"] = hist_dict[tagger][\"pt_loose_b\"].Clone()\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].Divide(hist_dict[tagger][\"pt_b\"])\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].SetMarkerStyle(21)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].SetMarkerColor(ROOT.kRed)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetYaxis().SetRangeUser(0,1)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetYaxis().SetTitle(\"b jet misid. efficiency\")\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetYaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetYaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetYaxis().SetTitleOffset(2.3)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetYaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetYaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetXaxis().SetTitle(\"jet p_{T} [GeV]\")\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetXaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetXaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetXaxis().SetTitleOffset(2.1)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetXaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].GetXaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"pt_loose_b_eff\"].Draw(\"p\")\n",
    "    \n",
    "    hist_dict[tagger][\"pt_b\"] = ROOT.TH1D(tagger+\"_pt_b\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_b\"].FillN(len(discriminator_dict['Jet_pt']['b']),discriminator_dict['Jet_pt']['b'],np.ones(len(discriminator_dict['Jet_pt']['b'])))\n",
    "    tag_mask_b_medium = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']>out_dict[tagger][\"medium\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['b']>out_dict[tagger][\"medium\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_medium_b\"] = ROOT.TH1D(tagger+\"_pt_medium_b\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_medium_b\"].FillN(len(discriminator_dict['Jet_pt']['b'][tag_mask_b_medium]),discriminator_dict['Jet_pt']['b'][tag_mask_b_medium],np.ones(len(discriminator_dict['Jet_pt']['b'][tag_mask_b_medium])))   \n",
    "    hist_dict[tagger][\"pt_medium_b_eff\"] = hist_dict[tagger][\"pt_medium_b\"].Clone()\n",
    "    hist_dict[tagger][\"pt_medium_b_eff\"].Divide(hist_dict[tagger][\"pt_b\"])\n",
    "    hist_dict[tagger][\"pt_medium_b_eff\"].SetMarkerStyle(22)\n",
    "    hist_dict[tagger][\"pt_medium_b_eff\"].SetMarkerColor(ROOT.kBlue)\n",
    "    hist_dict[tagger][\"pt_medium_b_eff\"].Draw(\"p same\")\n",
    "    \n",
    "    hist_dict[tagger][\"pt_b\"] = ROOT.TH1D(tagger+\"_pt_b\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_b\"].FillN(len(discriminator_dict['Jet_pt']['b']),discriminator_dict['Jet_pt']['b'],np.ones(len(discriminator_dict['Jet_pt']['b'])))\n",
    "    tag_mask_b_tight = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']>out_dict[tagger][\"tight\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['b']>out_dict[tagger][\"tight\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_tight_b\"] = ROOT.TH1D(tagger+\"_pt_tight_b\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_tight_b\"].FillN(len(discriminator_dict['Jet_pt']['b'][tag_mask_b_tight]),discriminator_dict['Jet_pt']['b'][tag_mask_b_tight],np.ones(len(discriminator_dict['Jet_pt']['b'][tag_mask_b_tight])))   \n",
    "    hist_dict[tagger][\"pt_tight_b_eff\"] = hist_dict[tagger][\"pt_tight_b\"].Clone()\n",
    "    hist_dict[tagger][\"pt_tight_b_eff\"].Divide(hist_dict[tagger][\"pt_b\"])\n",
    "    hist_dict[tagger][\"pt_tight_b_eff\"].SetMarkerStyle(28)\n",
    "    hist_dict[tagger][\"pt_tight_b_eff\"].SetMarkerColor(ROOT.kGreen+2)\n",
    "    hist_dict[tagger][\"pt_tight_b_eff\"].Draw(\"p same\")\n",
    "    \n",
    "    legend_dict[tagger]['pt_b'] = ROOT.TLegend(0.15,0.82,0.9,0.99)\n",
    "    legend_dict[tagger]['pt_b'].SetNColumns(3)\n",
    "    legend_dict[tagger]['pt_b'].SetTextFont(43)\n",
    "    legend_dict[tagger]['pt_b'].SetTextSize(20)\n",
    "    legend_dict[tagger]['pt_b'].SetBorderSize(0)\n",
    "    legend_dict[tagger]['pt_b'].SetFillStyle(0)\n",
    "    legend_dict[tagger]['pt_b'].SetHeader(tagger.replace(\"Flavour\",\"Jet\") + \" c tagger\")\n",
    "    legend_dict[tagger]['pt_b'].AddEntry(hist_dict[tagger][\"pt_loose_b_eff\"],\"Loose\",\"p\")\n",
    "    legend_dict[tagger]['pt_b'].AddEntry(hist_dict[tagger][\"pt_medium_b_eff\"],\"Medium\",\"p\")\n",
    "    legend_dict[tagger]['pt_b'].AddEntry(hist_dict[tagger][\"pt_tight_b_eff\"],\"Tight\",\"p\")\n",
    "    legend_dict[tagger]['pt_b'].Draw('same')\n",
    "    \n",
    "    # light pt\n",
    "    canvas_dict[tagger].cd(3)\n",
    "    ROOT.gPad.SetMargin(0.15,0.05,0.15,0.2)\n",
    "    hist_dict[tagger][\"pt_l\"] = ROOT.TH1D(tagger+\"_pt_l\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_l\"].FillN(len(discriminator_dict['Jet_pt']['l']),discriminator_dict['Jet_pt']['l'],np.ones(len(discriminator_dict['Jet_pt']['l'])))\n",
    "    tag_mask_l_loose = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']>out_dict[tagger][\"loose\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['l']>out_dict[tagger][\"loose\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_loose_l\"] = ROOT.TH1D(tagger+\"_pt_loose_l\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_loose_l\"].FillN(len(discriminator_dict['Jet_pt']['l'][tag_mask_l_loose]),discriminator_dict['Jet_pt']['l'][tag_mask_l_loose],np.ones(len(discriminator_dict['Jet_pt']['l'][tag_mask_l_loose])))   \n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"] = hist_dict[tagger][\"pt_loose_l\"].Clone()\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].Divide(hist_dict[tagger][\"pt_l\"])\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].SetMarkerStyle(21)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].SetMarkerColor(ROOT.kRed)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetYaxis().SetRangeUser(0,1)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetYaxis().SetTitle(\"light jet misid. efficiency\")\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetYaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetYaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetYaxis().SetTitleOffset(2.3)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetYaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetYaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetXaxis().SetTitle(\"jet p_{T} [GeV]\")\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetXaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetXaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetXaxis().SetTitleOffset(2.1)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetXaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].GetXaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"pt_loose_l_eff\"].Draw(\"p\")\n",
    "\n",
    "    hist_dict[tagger][\"pt_l\"] = ROOT.TH1D(tagger+\"_pt_l\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_l\"].FillN(len(discriminator_dict['Jet_pt']['l']),discriminator_dict['Jet_pt']['l'],np.ones(len(discriminator_dict['Jet_pt']['l'])))\n",
    "    tag_mask_l_medium = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']>out_dict[tagger][\"medium\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['l']>out_dict[tagger][\"medium\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_medium_l\"] = ROOT.TH1D(tagger+\"_pt_medium_l\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_medium_l\"].FillN(len(discriminator_dict['Jet_pt']['l'][tag_mask_l_medium]),discriminator_dict['Jet_pt']['l'][tag_mask_l_medium],np.ones(len(discriminator_dict['Jet_pt']['l'][tag_mask_l_medium])))   \n",
    "    hist_dict[tagger][\"pt_medium_l_eff\"] = hist_dict[tagger][\"pt_medium_l\"].Clone()\n",
    "    hist_dict[tagger][\"pt_medium_l_eff\"].Divide(hist_dict[tagger][\"pt_l\"])\n",
    "    hist_dict[tagger][\"pt_medium_l_eff\"].SetMarkerStyle(22)\n",
    "    hist_dict[tagger][\"pt_medium_l_eff\"].SetMarkerColor(ROOT.kBlue)\n",
    "    hist_dict[tagger][\"pt_medium_l_eff\"].Draw(\"p same\")\n",
    "\n",
    "    hist_dict[tagger][\"pt_l\"] = ROOT.TH1D(tagger+\"_pt_l\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_l\"].FillN(len(discriminator_dict['Jet_pt']['l']),discriminator_dict['Jet_pt']['l'],np.ones(len(discriminator_dict['Jet_pt']['l'])))\n",
    "    tag_mask_l_tight = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']>out_dict[tagger][\"tight\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['l']>out_dict[tagger][\"tight\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"pt_tight_l\"] = ROOT.TH1D(tagger+\"_pt_tight_l\",\"\",len(pt_bins)-1,array(\"d\",pt_bins))\n",
    "    hist_dict[tagger][\"pt_tight_l\"].FillN(len(discriminator_dict['Jet_pt']['l'][tag_mask_l_tight]),discriminator_dict['Jet_pt']['l'][tag_mask_l_tight],np.ones(len(discriminator_dict['Jet_pt']['l'][tag_mask_l_tight])))   \n",
    "    hist_dict[tagger][\"pt_tight_l_eff\"] = hist_dict[tagger][\"pt_tight_l\"].Clone()\n",
    "    hist_dict[tagger][\"pt_tight_l_eff\"].Divide(hist_dict[tagger][\"pt_l\"])\n",
    "    hist_dict[tagger][\"pt_tight_l_eff\"].SetMarkerStyle(28)\n",
    "    hist_dict[tagger][\"pt_tight_l_eff\"].SetMarkerColor(ROOT.kGreen+2)\n",
    "    hist_dict[tagger][\"pt_tight_l_eff\"].Draw(\"p same\")\n",
    "\n",
    "    legend_dict[tagger]['pt_l'] = ROOT.TLegend(0.15,0.82,0.9,0.99)\n",
    "    legend_dict[tagger]['pt_l'].SetNColumns(3)\n",
    "    legend_dict[tagger]['pt_l'].SetTextFont(43)\n",
    "    legend_dict[tagger]['pt_l'].SetTextSize(20)\n",
    "    legend_dict[tagger]['pt_l'].SetBorderSize(0)\n",
    "    legend_dict[tagger]['pt_l'].SetFillStyle(0)\n",
    "    legend_dict[tagger]['pt_l'].SetHeader(tagger.replace(\"Flavour\",\"Jet\") + \" c tagger\")\n",
    "    legend_dict[tagger]['pt_l'].AddEntry(hist_dict[tagger][\"pt_loose_l_eff\"],\"Loose\",\"p\")\n",
    "    legend_dict[tagger]['pt_l'].AddEntry(hist_dict[tagger][\"pt_medium_l_eff\"],\"Medium\",\"p\")\n",
    "    legend_dict[tagger]['pt_l'].AddEntry(hist_dict[tagger][\"pt_tight_l_eff\"],\"Tight\",\"p\")\n",
    "    legend_dict[tagger]['pt_l'].Draw('same')\n",
    "    \n",
    "    \n",
    "    \n",
    "    # eta, c jets\n",
    "    canvas_dict[tagger].cd(4)\n",
    "    ROOT.gPad.SetMargin(0.15,0.05,0.15,0.2)\n",
    "    hist_dict[tagger][\"eta_c\"] = ROOT.TH1D(tagger+\"_eta_c\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_c\"].FillN(len(discriminator_dict['Jet_eta']['c']),discriminator_dict['Jet_eta']['c'],np.ones(len(discriminator_dict['Jet_eta']['c'])))\n",
    "    tag_mask_c_loose = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']>out_dict[tagger][\"loose\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['c']>out_dict[tagger][\"loose\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_loose_c\"] = ROOT.TH1D(tagger+\"_eta_loose_c\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_loose_c\"].FillN(len(discriminator_dict['Jet_eta']['c'][tag_mask_c_loose]),discriminator_dict['Jet_eta']['c'][tag_mask_c_loose],np.ones(len(discriminator_dict['Jet_eta']['c'][tag_mask_c_loose])))   \n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"] = hist_dict[tagger][\"eta_loose_c\"].Clone()\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].Divide(hist_dict[tagger][\"eta_c\"])\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].SetMarkerStyle(21)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].SetMarkerColor(ROOT.kRed)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetYaxis().SetRangeUser(0,1)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetYaxis().SetTitle(\"c jet efficiency\")\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetYaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetYaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetYaxis().SetTitleOffset(2.3)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetYaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetYaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetXaxis().SetTitle(\"jet #eta\")\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetXaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetXaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetXaxis().SetTitleOffset(2.1)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetXaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].GetXaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"eta_loose_c_eff\"].Draw(\"p\")\n",
    "\n",
    "    hist_dict[tagger][\"eta_c\"] = ROOT.TH1D(tagger+\"_eta_c\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_c\"].FillN(len(discriminator_dict['Jet_eta']['c']),discriminator_dict['Jet_eta']['c'],np.ones(len(discriminator_dict['Jet_eta']['c'])))\n",
    "    tag_mask_c_medium = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']>out_dict[tagger][\"medium\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['c']>out_dict[tagger][\"medium\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_medium_c\"] = ROOT.TH1D(tagger+\"_eta_medium_c\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_medium_c\"].FillN(len(discriminator_dict['Jet_eta']['c'][tag_mask_c_medium]),discriminator_dict['Jet_eta']['c'][tag_mask_c_medium],np.ones(len(discriminator_dict['Jet_eta']['c'][tag_mask_c_medium])))   \n",
    "    hist_dict[tagger][\"eta_medium_c_eff\"] = hist_dict[tagger][\"eta_medium_c\"].Clone()\n",
    "    hist_dict[tagger][\"eta_medium_c_eff\"].Divide(hist_dict[tagger][\"eta_c\"])\n",
    "    hist_dict[tagger][\"eta_medium_c_eff\"].SetMarkerStyle(22)\n",
    "    hist_dict[tagger][\"eta_medium_c_eff\"].SetMarkerColor(ROOT.kBlue)\n",
    "    hist_dict[tagger][\"eta_medium_c_eff\"].Draw(\"p same\")\n",
    "\n",
    "    hist_dict[tagger][\"eta_c\"] = ROOT.TH1D(tagger+\"_eta_c\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_c\"].FillN(len(discriminator_dict['Jet_eta']['c']),discriminator_dict['Jet_eta']['c'],np.ones(len(discriminator_dict['Jet_eta']['c'])))\n",
    "    tag_mask_c_tight = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['c']>out_dict[tagger][\"tight\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['c']>out_dict[tagger][\"tight\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_tight_c\"] = ROOT.TH1D(tagger+\"_eta_tight_c\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_tight_c\"].FillN(len(discriminator_dict['Jet_eta']['c'][tag_mask_c_tight]),discriminator_dict['Jet_eta']['c'][tag_mask_c_tight],np.ones(len(discriminator_dict['Jet_eta']['c'][tag_mask_c_tight])))   \n",
    "    hist_dict[tagger][\"eta_tight_c_eff\"] = hist_dict[tagger][\"eta_tight_c\"].Clone()\n",
    "    hist_dict[tagger][\"eta_tight_c_eff\"].Divide(hist_dict[tagger][\"eta_c\"])\n",
    "    hist_dict[tagger][\"eta_tight_c_eff\"].SetMarkerStyle(28)\n",
    "    hist_dict[tagger][\"eta_tight_c_eff\"].SetMarkerColor(ROOT.kGreen+2)\n",
    "    hist_dict[tagger][\"eta_tight_c_eff\"].Draw(\"p same\")\n",
    "\n",
    "    legend_dict[tagger]['eta_c'] = ROOT.TLegend(0.15,0.82,0.9,0.99)\n",
    "    legend_dict[tagger]['eta_c'].SetNColumns(3)\n",
    "    legend_dict[tagger]['eta_c'].SetTextFont(43)\n",
    "    legend_dict[tagger]['eta_c'].SetTextSize(20)\n",
    "    legend_dict[tagger]['eta_c'].SetBorderSize(0)\n",
    "    legend_dict[tagger]['eta_c'].SetFillStyle(0)\n",
    "    legend_dict[tagger]['eta_c'].SetHeader(tagger.replace(\"Flavour\",\"Jet\") + \" c tagger\")\n",
    "    legend_dict[tagger]['eta_c'].AddEntry(hist_dict[tagger][\"eta_loose_c_eff\"],\"Loose\",\"p\")\n",
    "    legend_dict[tagger]['eta_c'].AddEntry(hist_dict[tagger][\"eta_medium_c_eff\"],\"Medium\",\"p\")\n",
    "    legend_dict[tagger]['eta_c'].AddEntry(hist_dict[tagger][\"eta_tight_c_eff\"],\"Tight\",\"p\")\n",
    "    legend_dict[tagger]['eta_c'].Draw('same')\n",
    "    \n",
    "    # eta, b jets\n",
    "    canvas_dict[tagger].cd(5)\n",
    "    ROOT.gPad.SetMargin(0.15,0.05,0.15,0.2)\n",
    "    hist_dict[tagger][\"eta_b\"] = ROOT.TH1D(tagger+\"_eta_b\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_b\"].FillN(len(discriminator_dict['Jet_eta']['b']),discriminator_dict['Jet_eta']['b'],np.ones(len(discriminator_dict['Jet_eta']['b'])))\n",
    "    tag_mask_b_loose = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']>out_dict[tagger][\"loose\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['b']>out_dict[tagger][\"loose\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_loose_b\"] = ROOT.TH1D(tagger+\"_eta_loose_b\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_loose_b\"].FillN(len(discriminator_dict['Jet_eta']['b'][tag_mask_b_loose]),discriminator_dict['Jet_eta']['b'][tag_mask_b_loose],np.ones(len(discriminator_dict['Jet_eta']['b'][tag_mask_b_loose])))   \n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"] = hist_dict[tagger][\"eta_loose_b\"].Clone()\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].Divide(hist_dict[tagger][\"eta_b\"])\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].SetMarkerStyle(21)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].SetMarkerColor(ROOT.kRed)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetYaxis().SetRangeUser(0,1)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetYaxis().SetTitle(\"b jet misid. efficiency\")\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetYaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetYaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetYaxis().SetTitleOffset(2.3)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetYaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetYaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetXaxis().SetTitle(\"jet #eta\")\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetXaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetXaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetXaxis().SetTitleOffset(2.1)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetXaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].GetXaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"eta_loose_b_eff\"].Draw(\"p\")\n",
    "    \n",
    "    hist_dict[tagger][\"eta_b\"] = ROOT.TH1D(tagger+\"_eta_b\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_b\"].FillN(len(discriminator_dict['Jet_eta']['b']),discriminator_dict['Jet_eta']['b'],np.ones(len(discriminator_dict['Jet_eta']['b'])))\n",
    "    tag_mask_b_medium = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']>out_dict[tagger][\"medium\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['b']>out_dict[tagger][\"medium\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_medium_b\"] = ROOT.TH1D(tagger+\"_eta_medium_b\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_medium_b\"].FillN(len(discriminator_dict['Jet_eta']['b'][tag_mask_b_medium]),discriminator_dict['Jet_eta']['b'][tag_mask_b_medium],np.ones(len(discriminator_dict['Jet_eta']['b'][tag_mask_b_medium])))   \n",
    "    hist_dict[tagger][\"eta_medium_b_eff\"] = hist_dict[tagger][\"eta_medium_b\"].Clone()\n",
    "    hist_dict[tagger][\"eta_medium_b_eff\"].Divide(hist_dict[tagger][\"eta_b\"])\n",
    "    hist_dict[tagger][\"eta_medium_b_eff\"].SetMarkerStyle(22)\n",
    "    hist_dict[tagger][\"eta_medium_b_eff\"].SetMarkerColor(ROOT.kBlue)\n",
    "    hist_dict[tagger][\"eta_medium_b_eff\"].Draw(\"p same\")\n",
    "    \n",
    "    hist_dict[tagger][\"eta_b\"] = ROOT.TH1D(tagger+\"_eta_b\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_b\"].FillN(len(discriminator_dict['Jet_eta']['b']),discriminator_dict['Jet_eta']['b'],np.ones(len(discriminator_dict['Jet_eta']['b'])))\n",
    "    tag_mask_b_tight = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['b']>out_dict[tagger][\"tight\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['b']>out_dict[tagger][\"tight\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_tight_b\"] = ROOT.TH1D(tagger+\"_eta_tight_b\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_tight_b\"].FillN(len(discriminator_dict['Jet_eta']['b'][tag_mask_b_tight]),discriminator_dict['Jet_eta']['b'][tag_mask_b_tight],np.ones(len(discriminator_dict['Jet_eta']['b'][tag_mask_b_tight])))   \n",
    "    hist_dict[tagger][\"eta_tight_b_eff\"] = hist_dict[tagger][\"eta_tight_b\"].Clone()\n",
    "    hist_dict[tagger][\"eta_tight_b_eff\"].Divide(hist_dict[tagger][\"eta_b\"])\n",
    "    hist_dict[tagger][\"eta_tight_b_eff\"].SetMarkerStyle(28)\n",
    "    hist_dict[tagger][\"eta_tight_b_eff\"].SetMarkerColor(ROOT.kGreen+2)\n",
    "    hist_dict[tagger][\"eta_tight_b_eff\"].Draw(\"p same\")\n",
    "    \n",
    "    legend_dict[tagger]['eta_b'] = ROOT.TLegend(0.15,0.82,0.9,0.99)\n",
    "    legend_dict[tagger]['eta_b'].SetNColumns(3)\n",
    "    legend_dict[tagger]['eta_b'].SetTextFont(43)\n",
    "    legend_dict[tagger]['eta_b'].SetTextSize(20)\n",
    "    legend_dict[tagger]['eta_b'].SetBorderSize(0)\n",
    "    legend_dict[tagger]['eta_b'].SetFillStyle(0)\n",
    "    legend_dict[tagger]['eta_b'].SetHeader(tagger.replace(\"Flavour\",\"Jet\") + \" c tagger\")\n",
    "    legend_dict[tagger]['eta_b'].AddEntry(hist_dict[tagger][\"eta_loose_b_eff\"],\"Loose\",\"p\")\n",
    "    legend_dict[tagger]['eta_b'].AddEntry(hist_dict[tagger][\"eta_medium_b_eff\"],\"Medium\",\"p\")\n",
    "    legend_dict[tagger]['eta_b'].AddEntry(hist_dict[tagger][\"eta_tight_b_eff\"],\"Tight\",\"p\")\n",
    "    legend_dict[tagger]['eta_b'].Draw('same')\n",
    "    \n",
    "    # light eta\n",
    "    canvas_dict[tagger].cd(6)\n",
    "    ROOT.gPad.SetMargin(0.15,0.05,0.15,0.2)\n",
    "    hist_dict[tagger][\"eta_l\"] = ROOT.TH1D(tagger+\"_eta_l\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_l\"].FillN(len(discriminator_dict['Jet_eta']['l']),discriminator_dict['Jet_eta']['l'],np.ones(len(discriminator_dict['Jet_eta']['l'])))\n",
    "    tag_mask_l_loose = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']>out_dict[tagger][\"loose\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['l']>out_dict[tagger][\"loose\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_loose_l\"] = ROOT.TH1D(tagger+\"_eta_loose_l\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_loose_l\"].FillN(len(discriminator_dict['Jet_eta']['l'][tag_mask_l_loose]),discriminator_dict['Jet_eta']['l'][tag_mask_l_loose],np.ones(len(discriminator_dict['Jet_eta']['l'][tag_mask_l_loose])))   \n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"] = hist_dict[tagger][\"eta_loose_l\"].Clone()\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].Divide(hist_dict[tagger][\"eta_l\"])\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].SetMarkerStyle(21)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].SetMarkerColor(ROOT.kRed)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetYaxis().SetRangeUser(0,1)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetYaxis().SetTitle(\"light jet misid. efficiency\")\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetYaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetYaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetYaxis().SetTitleOffset(2.3)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetYaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetYaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetXaxis().SetTitle(\"jet #eta\")\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetXaxis().SetTitleFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetXaxis().SetTitleSize(20)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetXaxis().SetTitleOffset(2.1)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetXaxis().SetLabelFont(43)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].GetXaxis().SetLabelSize(15)\n",
    "    hist_dict[tagger][\"eta_loose_l_eff\"].Draw(\"p\")\n",
    "\n",
    "    hist_dict[tagger][\"eta_l\"] = ROOT.TH1D(tagger+\"_eta_l\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_l\"].FillN(len(discriminator_dict['Jet_eta']['l']),discriminator_dict['Jet_eta']['l'],np.ones(len(discriminator_dict['Jet_eta']['l'])))\n",
    "    tag_mask_l_medium = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']>out_dict[tagger][\"medium\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['l']>out_dict[tagger][\"medium\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_medium_l\"] = ROOT.TH1D(tagger+\"_eta_medium_l\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_medium_l\"].FillN(len(discriminator_dict['Jet_eta']['l'][tag_mask_l_medium]),discriminator_dict['Jet_eta']['l'][tag_mask_l_medium],np.ones(len(discriminator_dict['Jet_eta']['l'][tag_mask_l_medium])))   \n",
    "    hist_dict[tagger][\"eta_medium_l_eff\"] = hist_dict[tagger][\"eta_medium_l\"].Clone()\n",
    "    hist_dict[tagger][\"eta_medium_l_eff\"].Divide(hist_dict[tagger][\"eta_l\"])\n",
    "    hist_dict[tagger][\"eta_medium_l_eff\"].SetMarkerStyle(22)\n",
    "    hist_dict[tagger][\"eta_medium_l_eff\"].SetMarkerColor(ROOT.kBlue)\n",
    "    hist_dict[tagger][\"eta_medium_l_eff\"].Draw(\"p same\")\n",
    "\n",
    "    hist_dict[tagger][\"eta_l\"] = ROOT.TH1D(tagger+\"_eta_l\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_l\"].FillN(len(discriminator_dict['Jet_eta']['l']),discriminator_dict['Jet_eta']['l'],np.ones(len(discriminator_dict['Jet_eta']['l'])))\n",
    "    tag_mask_l_tight = (discriminator_dict['Jet_%sCvsLDisc'%tagger]['l']>out_dict[tagger][\"tight\"][\"cut CvsL\"])*(discriminator_dict['Jet_%sCvsBDisc'%tagger]['l']>out_dict[tagger][\"tight\"][\"cut CvsB\"])  \n",
    "    hist_dict[tagger][\"eta_tight_l\"] = ROOT.TH1D(tagger+\"_eta_tight_l\",\"\",len(eta_bins)-1,array(\"d\",eta_bins))\n",
    "    hist_dict[tagger][\"eta_tight_l\"].FillN(len(discriminator_dict['Jet_eta']['l'][tag_mask_l_tight]),discriminator_dict['Jet_eta']['l'][tag_mask_l_tight],np.ones(len(discriminator_dict['Jet_eta']['l'][tag_mask_l_tight])))   \n",
    "    hist_dict[tagger][\"eta_tight_l_eff\"] = hist_dict[tagger][\"eta_tight_l\"].Clone()\n",
    "    hist_dict[tagger][\"eta_tight_l_eff\"].Divide(hist_dict[tagger][\"eta_l\"])\n",
    "    hist_dict[tagger][\"eta_tight_l_eff\"].SetMarkerStyle(28)\n",
    "    hist_dict[tagger][\"eta_tight_l_eff\"].SetMarkerColor(ROOT.kGreen+2)\n",
    "    hist_dict[tagger][\"eta_tight_l_eff\"].Draw(\"p same\")\n",
    "\n",
    "    legend_dict[tagger]['eta_l'] = ROOT.TLegend(0.15,0.82,0.9,0.99)\n",
    "    legend_dict[tagger]['eta_l'].SetNColumns(3)\n",
    "    legend_dict[tagger]['eta_l'].SetTextFont(43)\n",
    "    legend_dict[tagger]['eta_l'].SetTextSize(20)\n",
    "    legend_dict[tagger]['eta_l'].SetBorderSize(0)\n",
    "    legend_dict[tagger]['eta_l'].SetFillStyle(0)\n",
    "    legend_dict[tagger]['eta_l'].SetHeader(tagger.replace(\"Flavour\",\"Jet\") + \" c tagger\")\n",
    "    legend_dict[tagger]['eta_l'].AddEntry(hist_dict[tagger][\"eta_loose_l_eff\"],\"Loose\",\"p\")\n",
    "    legend_dict[tagger]['eta_l'].AddEntry(hist_dict[tagger][\"eta_medium_l_eff\"],\"Medium\",\"p\")\n",
    "    legend_dict[tagger]['eta_l'].AddEntry(hist_dict[tagger][\"eta_tight_l_eff\"],\"Tight\",\"p\")\n",
    "    legend_dict[tagger]['eta_l'].Draw('same')\n",
    "    \n",
    "    \n",
    "    canvas_dict[tagger].Draw()\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/Efficiency_vs_pt_eta_%s.pdf\"%tagger)\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/Efficiency_vs_pt_eta_%s.png\"%tagger)\n",
    "    canvas_dict[tagger].SaveAs(\"./plots/Efficiency_vs_pt_eta_%s.C\"%tagger)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#os.system('dasgoclient -query=\"file dataset=/QCD_Pt_80to120_TuneCP5_13TeV_pythia8/RunIISummer19UL18NanoAOD-PUForMUOVal_106X_upgrade2018_realistic_v11_L1v1-v3/NANOAODSIM\" > files.txt')\n",
    "#os.system('dasgoclient -query=\"file dataset=/TTTo2L2Nu_TuneCP5up_13TeV-powheg-pythia8/RunIISummer19UL18NanoAOD-106X_upgrade2018_realistic_v11_L1v1-v2/NANOAODSIM\" > files.txt')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# input_files = open(\"files.txt\",\"r\")\n",
    "# infile_array = []\n",
    "# for idx,f_ in enumerate(input_files.readlines()):\n",
    "#     infile_array.append(f_.replace(\"\\n\",\"\"))\n",
    "    \n",
    "# input_files.close()\n",
    "# print \"found %i files in 'files.txt'\"%(idx+1)\n",
    "# #print infile_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# f = uproot.open('root://xrootd-cms.infn.it//store/user/smoortga/BTagServiceWork/CTaggerWPs_2017_UltraLegacy/QCD_Pt_80to120_TuneCP5_13TeV_pythia8_RunIISummer19UL17MiniAOD-106X_mc2017_realistic_v6-v2_MINIAODSIM/QCD_Pt_80to120_TuneCP5_13TeV_pythia8/crab_BTagAnalyzer_CTagWP_2017_UltraLegacy/200116_133349/0000/JetTree_mc_1.root')\n",
    "# t = f['btagana/ttree']\n",
    "# t.keys()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15+"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
